{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T04:11:50.173831Z",
     "iopub.status.busy": "2025-06-02T04:11:50.173502Z",
     "iopub.status.idle": "2025-06-02T04:12:10.237881Z",
     "shell.execute_reply": "2025-06-02T04:12:10.237211Z",
     "shell.execute_reply.started": "2025-06-02T04:11:50.173797Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions.normal import Normal\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.optim as optim\n",
    "import torchio as tio\n",
    "from torchinfo import summary\n",
    "from scipy.spatial import Delaunay\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "import math\n",
    "import nibabel as nib\n",
    "import nrrd\n",
    "import SimpleITK as sitk\n",
    "import time\n",
    "#from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import json\n",
    "from natsort import natsorted\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T04:12:10.239055Z",
     "iopub.status.busy": "2025-06-02T04:12:10.238551Z",
     "iopub.status.idle": "2025-06-02T04:12:10.252114Z",
     "shell.execute_reply": "2025-06-02T04:12:10.251366Z",
     "shell.execute_reply.started": "2025-06-02T04:12:10.239027Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class LinearInterpolation3d(nn.Module):\n",
    "    def __init__(self, size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.size = size\n",
    "\n",
    "        grid = F.affine_grid(torch.eye(3, 4).unsqueeze(0), (1, 1)+size, align_corners=True).view(1, -1, 3)\n",
    "        self.register_buffer(\"grid\", grid)\n",
    "\n",
    "        pads = torch.ones((1, 8, 3))\n",
    "        pads[0, 1, 0] = -1\n",
    "        pads[0, 2, 1] = -1\n",
    "        pads[0, 3, 2] = -1\n",
    "        pads[0, 4, 0] = -1\n",
    "        pads[0, 4, 1] = -1\n",
    "        pads[0, 5, 0] = -1\n",
    "        pads[0, 5, 2] = -1\n",
    "        pads[0, 6, 1] = -1\n",
    "        pads[0, 6, 2] = -1\n",
    "        pads[0, 7, 0] = -1\n",
    "        pads[0, 7, 1] = -1\n",
    "        pads[0, 7, 2] = -1\n",
    "        self.register_buffer(\"pads\", pads)\n",
    "\n",
    "        pads_values = torch.zeros((1, 8, 3))\n",
    "        self.register_buffer(\"pads_values\", pads_values)\n",
    "    \n",
    "    def _get_barycentric_coordinates(self, points_tri, target):\n",
    "        s = points_tri.find_simplex(target)\n",
    "        dim = target.shape[1]\n",
    "        \n",
    "        b0 = (points_tri.transform[s, :dim].transpose([1, 0, 2]) *\n",
    "            (target - points_tri.transform[s, dim])).sum(axis=2).T\n",
    "        coord = np.c_[b0, 1 - b0.sum(axis=1)]\n",
    "\n",
    "        return coord, s\n",
    "\n",
    "    def _linear_interp_material(self, points, target):\n",
    "        \"\"\"\n",
    "        Linearly interpolate signal at target locations\n",
    "        points: numpy array (N, D)\n",
    "        target: numpy array (N, D)\n",
    "        \"\"\"\n",
    "        points_triangulated = Delaunay(points)\n",
    "        c, s = self._get_barycentric_coordinates(points_triangulated, target)\n",
    "        \n",
    "        return points_triangulated.simplices, points_triangulated.transform, c, s\n",
    "    \n",
    "    def _linear_interp(self, points, values, target):\n",
    "        \"\"\"\n",
    "        points: points where the signal is known; torch tensor (B, N, D)\n",
    "        values: signal; torch tensor (B, N, C)\n",
    "        target: where the signal needs to be interpolated; torch tensor (B, M, D)\n",
    "        \"\"\"\n",
    "        device = points.device\n",
    "        B = points.size(0)\n",
    "\n",
    "        if B>1:\n",
    "            raise NotImplementedError(\"Linear interpolation not implemented for batches larger than 1.\")\n",
    "\n",
    "        points_np = points.detach().cpu().numpy()\n",
    "        target_np = target.detach().cpu().numpy()\n",
    "            \n",
    "        simplices, T, coords, s = self._linear_interp_material(points_np[0], target_np[0])\n",
    "        simplices = torch.tensor(simplices).long().to(device)  # n_simplices, D+1\n",
    "        T = torch.tensor(T).float().to(device) # n_simplices, D+1\n",
    "        coords = torch.tensor(coords).float().to(device) # M, D+1\n",
    "        s = torch.tensor(s).long().to(device) # M\n",
    "\n",
    "        res = (values[0, simplices[s]] * coords[:, :, None]).sum(1) # M,C\n",
    "            \n",
    "        return res[None, :]\n",
    "    \n",
    "    def forward(self, kpts, disp):\n",
    "        \"\"\"\n",
    "        kpts: B, N, 3\n",
    "        disp: B, N, 3\n",
    "        \"\"\"\n",
    "        kpts_pad = torch.cat([kpts, self.pads], dim=1)\n",
    "        disp_pad = torch.cat([disp, self.pads_values], dim=1)\n",
    "        interp = self._linear_interp(kpts_pad, disp_pad, self.grid)\n",
    "        return torch.reshape(interp, (kpts.size(0),)+self.size+(3,)).permute(0, 4, 1, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T04:12:10.254972Z",
     "iopub.status.busy": "2025-06-02T04:12:10.254355Z",
     "iopub.status.idle": "2025-06-02T04:12:10.304603Z",
     "shell.execute_reply": "2025-06-02T04:12:10.303848Z",
     "shell.execute_reply.started": "2025-06-02T04:12:10.254942Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ThinPlateSpline(nn.Module):\n",
    "    def __init__(self, shape, step=4, lambd=0.1, unroll_step_size=2**12):\n",
    "        super().__init__()\n",
    "        self.shape = shape  # Output grid shape: (D, H, W)\n",
    "        self.step = step    # Downsampling step for coarse grid\n",
    "        self.lambd = lambd\n",
    "        self.unroll_step_size = unroll_step_size\n",
    "\n",
    "        # Precompute the identity affine grid for interpolation\n",
    "        D1, H1, W1 = [s // step for s in shape]\n",
    "        grid = F.affine_grid(\n",
    "            torch.eye(3, 4).unsqueeze(0),  # Identity\n",
    "            size=(1, 1, D1, H1, W1),\n",
    "            align_corners=True\n",
    "        )\n",
    "        self.register_buffer(\"base_grid\", grid.view(-1, 3))  # Flattened 3D grid\n",
    "\n",
    "    def forward(self, kpts, disps):\n",
    "        \"\"\"\n",
    "        kpts: (1, N, 3) - keypoints from source\n",
    "        disps: (1, N, 3) - corresponding displacements\n",
    "        Returns: dense displacement field of shape (1, 3, D, H, W)\n",
    "        \"\"\"\n",
    "        x1 = kpts[0]  # (N, 3)\n",
    "        y1 = disps[0]  # (N, 3)\n",
    "        x2 = self.base_grid    # (M, 3) - dense grid to warp\n",
    "\n",
    "        # Compute TPS parameters\n",
    "        theta = self._fit(x1, y1)\n",
    "\n",
    "        # Compute transformed grid\n",
    "        M = x2.shape[0]\n",
    "        y2 = torch.zeros((1, M, 3), device=x2.device)\n",
    "\n",
    "        n_chunks = math.ceil(M / self.unroll_step_size)\n",
    "        for j in range(n_chunks):\n",
    "            j1 = j * self.unroll_step_size\n",
    "            j2 = min((j + 1) * self.unroll_step_size, M)\n",
    "            y2[0, j1:j2, :] = self._z(x2[j1:j2], x1, theta)\n",
    "\n",
    "        # Reshape and interpolate back to full resolution\n",
    "        D1, H1, W1 = [s // self.step for s in self.shape]\n",
    "        y2 = y2.view(1, D1, H1, W1, 3).permute(0, 4, 1, 2, 3)  # (1, 3, D1, H1, W1)\n",
    "        y2 = F.interpolate(y2, size=self.shape, mode='trilinear', align_corners=True)\n",
    "        return y2\n",
    "\n",
    "    def _fit(self, c, f):\n",
    "        \"\"\"Compute TPS parameters (theta)\"\"\"\n",
    "        device = c.device\n",
    "        n = c.shape[0]\n",
    "        f_dim = f.shape[1]\n",
    "\n",
    "        U = self._u(self._d(c, c))  # (n, n)\n",
    "        K = U + torch.eye(n, device=device) * self.lambd\n",
    "\n",
    "        P = torch.ones((n, 4), device=device)\n",
    "        P[:, 1:] = c\n",
    "\n",
    "        v = torch.zeros((n + 4, f_dim), device=device)\n",
    "        v[:n, :] = f\n",
    "\n",
    "        A = torch.zeros((n + 4, n + 4), device=device)\n",
    "        A[:n, :n] = K\n",
    "        A[:n, -4:] = P\n",
    "        A[-4:, :n] = P.t()\n",
    "\n",
    "        theta = torch.linalg.solve(A, v)\n",
    "        return theta\n",
    "\n",
    "    def _z(self, x, c, theta):\n",
    "        \"\"\"Apply TPS transformation\"\"\"\n",
    "        U = self._u(self._d(x, c))\n",
    "        w, a = theta[:-4], theta[-4:].unsqueeze(2)\n",
    "        b = torch.matmul(U, w)  # (M, 3)\n",
    "        return (a[0] + a[1] * x[:, 0] + a[2] * x[:, 1] + a[3] * x[:, 2] + b.t()).t()\n",
    "\n",
    "    def _d(self, a, b):\n",
    "        \"\"\"Pairwise Euclidean distances\"\"\"\n",
    "        ra = (a ** 2).sum(dim=1).view(-1, 1)\n",
    "        rb = (b ** 2).sum(dim=1).view(1, -1)\n",
    "        dist = ra + rb - 2.0 * torch.mm(a, b.T)\n",
    "        return torch.sqrt(torch.clamp(dist, min=0.0))\n",
    "\n",
    "    def _u(self, r):\n",
    "        \"\"\"Radial basis function for TPS\"\"\"\n",
    "        return (r ** 2) * torch.log(r + 1e-6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T04:12:10.305760Z",
     "iopub.status.busy": "2025-06-02T04:12:10.305467Z",
     "iopub.status.idle": "2025-06-02T04:12:10.322866Z",
     "shell.execute_reply": "2025-06-02T04:12:10.322114Z",
     "shell.execute_reply.started": "2025-06-02T04:12:10.305738Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class NeuriPhyDataset(Dataset):\n",
    "    def __init__(self, path, out_size=(240,240,155), mode='train', normalization=None, ddf_interpolator='linear'):\n",
    "        self.data = natsorted(glob.glob(os.path.join(path, \"*\")))\n",
    "        self.mode = mode\n",
    "        self.normalization = normalization\n",
    "        self.ddf_interp = ddf_interpolator\n",
    "        self.out_size = out_size\n",
    "\n",
    "    def preprocess(self, img, mask):\n",
    "        if self.normalization is not None:\n",
    "            mask = mask > 0\n",
    "            if self.normalization == 'standard':\n",
    "                mean = img[mask].mean()\n",
    "                std = img[mask].std()\n",
    "                img = (img - mean) / (std + 1e-8)\n",
    "            elif self.normalization == 'min-max':\n",
    "                max_data = np.percentile(img, 99.95)\n",
    "                min_data = img[mask].min()\n",
    "                img = (img - min_data) / (max_data - min_data)\n",
    "            else:\n",
    "                raise NotImplementedError(f\"Normalization '{self.normalization}' should be in ['min-max', 'standard']\")\n",
    "        return torch.tensor(img.astype(np.float32))\n",
    "\n",
    "    def initialize_disp_field(self, kpts, gt_ddf, tumor_seg, min_kpts=5, max_kpts=20):\n",
    "        _, D, H, W = gt_ddf.shape\n",
    "\n",
    "        if self.ddf_interp == 'linear':\n",
    "            ddf_interp = LinearInterpolation3d((D,H,W))\n",
    "        elif self.ddf_interp == 'tps':\n",
    "            ddf_interp = ThinPlateSpline((D,H,W))\n",
    "\n",
    "        kpts = np.genfromtxt(kpts, delimiter=\"\\t\", skip_header=6, dtype=np.float32)[:,:3]\n",
    "        _, unique_idxs = np.unique(kpts, axis=0, return_index=True)\n",
    "        sorted_unique_idxs = np.sort(unique_idxs)\n",
    "        kpts = kpts[sorted_unique_idxs]\n",
    "        kpts[:, 0] = (kpts[:, 0] / (D - 1)) * 2 - 1\n",
    "        kpts[:, 1] = (kpts[:, 1] / (H - 1)) * 2 - 1\n",
    "        kpts[:, 2] = (kpts[:, 2] / (W - 1)) * 2 - 1\n",
    "\n",
    "        tumor_coords = np.argwhere(tumor_seg > 0)\n",
    "        tumor_center = np.mean(tumor_coords, axis=0)\n",
    "        distances = cdist(tumor_center.reshape(1,-1), kpts)\n",
    "        weight = np.exp(-distances[0])\n",
    "        weight /= np.sum(weight)\n",
    "\n",
    "        k = np.random.randint(min_kpts, max_kpts+1)\n",
    "        choices = np.random.choice(range(kpts.shape[0]), p=weight, size=k, replace=False)\n",
    "        kpts = kpts[choices]\n",
    "        kpts = torch.from_numpy(kpts)\n",
    "        grid = kpts.view(1, -1, 1, 1, 3)\n",
    "        sampled_disps = F.grid_sample(gt_ddf.unsqueeze(0), grid, mode='bilinear', align_corners=True).permute(2,1,0,3,4).squeeze()\n",
    "\n",
    "        #pad = torch.full((max_kpts-k,3), -1.0, dtype=kpts.dtype)\n",
    "        #pad_mask = torch.zeros(max_kpts, dtype=torch.bool)\n",
    "        #pad_mask[:k] = 1\n",
    "        #kpts = torch.cat([kpts, pad], dim=0)\n",
    "        #sampled_disps = torch.cat([sampled_disps, pad], dim=0)\n",
    "\n",
    "        init_ddf = ddf_interp(kpts.unsqueeze(0), sampled_disps.unsqueeze(0)).squeeze(0)  # (3, D, H, W)\n",
    "\n",
    "        return init_ddf\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        curr_data = self.data[idx]\n",
    "        brain_seg = glob.glob(os.path.join(curr_data, \"segmentations\", \"*brain_mask*.seg.nrrd\"))[0]\n",
    "        tumor_seg = glob.glob(os.path.join(curr_data, \"segmentations\", \"*tumor*.seg.nrrd\"))[0]\n",
    "        gt_ddf = glob.glob(os.path.join(curr_data, \"simulations\", \"simulation*\", \"*disp_field*.npz\"))[0] # todo: right now only using one\n",
    "        t1ce = glob.glob(os.path.join(curr_data, \"images\", \"*T1ce*.nii\"))\n",
    "        if len(t1ce) > 0:\n",
    "            kpts = glob.glob(os.path.join(curr_data, \"keypoints\", \"*T1ce.key\"))[0]\n",
    "            img = nib.load(t1ce[0]).get_fdata()\n",
    "        else:\n",
    "            kpts = glob.glob(os.path.join(curr_data, \"keypoints\", \"*T2.key\"))[0]\n",
    "            t2 = glob.glob(os.path.join(curr_data, \"images\", \"*T2*.nii\"))\n",
    "            img = nib.load(t2[0]).get_fdata()\n",
    "        \n",
    "        brain_seg, _ = nrrd.read(brain_seg)\n",
    "        tumor_seg, _ = nrrd.read(tumor_seg)\n",
    "        gt_ddf = np.load(gt_ddf)['field'].transpose(0,3,2,1)\n",
    "        gt_ddf = torch.tensor(gt_ddf.astype(np.float32))\n",
    "        brain_seg = torch.tensor(brain_seg.astype(np.float32))\n",
    "\n",
    "        img = self.preprocess(img, brain_seg)\n",
    "\n",
    "        init_ddf = self.initialize_disp_field(kpts, gt_ddf, tumor_seg)\n",
    "\n",
    "        subject = tio.Subject(\n",
    "            img=tio.ScalarImage(tensor=img.unsqueeze(0)),\n",
    "            brain_seg=tio.LabelMap(tensor=brain_seg.unsqueeze(0)),\n",
    "            gt_ddf = tio.ScalarImage(tensor=gt_ddf),\n",
    "            init_ddf = tio.ScalarImage(tensor=init_ddf)\n",
    "        )\n",
    "        transform = tio.CropOrPad(self.out_size)\n",
    "        transformed = transform(subject)\n",
    "            \n",
    "            #img = F.interpolate(img.unsqueeze(0).unsqueeze(0), self.out_size, mode='trilinear', align_corners=True).squeeze(0)\n",
    "            #brain_seg = F.interpolate(brain_seg.unsqueeze(0).unsqueeze(0), self.out_size, mode='nearest').squeeze(0).squeeze(0)\n",
    "            #gt_ddf = F.interpolate(gt_ddf.unsqueeze(0), self.out_size, mode='trilinear', align_corners=True).squeeze(0)\n",
    "            #init_ddf = F.interpolate(init_ddf.unsqueeze(0), self.out_size, mode='trilinear', align_corners=True).squeeze(0)\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            return transformed['img'].tensor, transformed['init_ddf'].tensor, transformed['gt_ddf'].tensor, transformed['brain_seg'].tensor\n",
    "        elif self.mode == 'test':\n",
    "            return transformed['img'].tensor, transformed['init_ddf'].tensor, transformed['brain_seg'].tensor\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T04:12:10.323869Z",
     "iopub.status.busy": "2025-06-02T04:12:10.323694Z",
     "iopub.status.idle": "2025-06-02T04:12:10.342245Z",
     "shell.execute_reply": "2025-06-02T04:12:10.341554Z",
     "shell.execute_reply.started": "2025-06-02T04:12:10.323854Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class InitWeights_He(object):\n",
    "    def __init__(self, neg_slope=1e-2):\n",
    "        self.neg_slope = neg_slope\n",
    "\n",
    "    def __call__(self, module):\n",
    "        if isinstance(module, nn.Conv3d) or isinstance(module, nn.Conv2d) or isinstance(module, nn.ConvTranspose2d) or isinstance(module, nn.ConvTranspose3d):\n",
    "            module.weight = nn.init.kaiming_normal_(module.weight, a=self.neg_slope)\n",
    "            if module.bias is not None:\n",
    "                module.bias = nn.init.constant_(module.bias, 0)\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Specific convolutional block followed by leakyrelu for unet.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ndims, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        Conv = getattr(nn, 'Conv%dd' % ndims)\n",
    "        self.main = Conv(in_channels, out_channels, 3, stride, 1)\n",
    "        self.activation = nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.main(x)\n",
    "        out = self.activation(out)\n",
    "        return out\n",
    "    \n",
    "\n",
    "class Unet(nn.Module):\n",
    "    \"\"\"\n",
    "    A unet architecture. Layer features can be specified directly as a list of encoder and decoder\n",
    "    features or as a single integer along with a number of unet levels. The default network features\n",
    "    per layer (when no options are specified) are:\n",
    "\n",
    "        encoder: [16, 32, 32, 32]\n",
    "        decoder: [32, 32, 32, 32, 32, 16, 16]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 inshape=None,\n",
    "                 infeats=None,\n",
    "                 nb_features=None,\n",
    "                 nb_levels=None,\n",
    "                 max_pool=2,\n",
    "                 feat_mult=1,\n",
    "                 nb_conv_per_level=1,\n",
    "                 half_res=False):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            inshape: Input shape. e.g. (192, 192, 192)\n",
    "            infeats: Number of input features.\n",
    "            nb_features: Unet convolutional features. Can be specified via a list of lists with\n",
    "                the form [[encoder feats], [decoder feats]], or as a single integer. \n",
    "                If None (default), the unet features are defined by the default config described in \n",
    "                the class documentation.\n",
    "            nb_levels: Number of levels in unet. Only used when nb_features is an integer. \n",
    "                Default is None.\n",
    "            feat_mult: Per-level feature multiplier. Only used when nb_features is an integer. \n",
    "                Default is 1.\n",
    "            nb_conv_per_level: Number of convolutions per unet level. Default is 1.\n",
    "            half_res: Skip the last decoder upsampling. Default is False.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # ensure correct dimensionality\n",
    "        ndims = len(inshape)\n",
    "        assert ndims in [1, 2, 3], 'ndims should be one of 1, 2, or 3. found: %d' % ndims\n",
    "\n",
    "        # cache some parameters\n",
    "        self.half_res = half_res\n",
    "\n",
    "        # default encoder and decoder layer features if nothing provided\n",
    "        if nb_features is None:\n",
    "            nb_features = [\n",
    "                [16, 32, 32, 32],             # encoder\n",
    "                [32, 32, 32, 32, 32, 16, 16]  # decoder\n",
    "            ]\n",
    "\n",
    "        # build feature list automatically\n",
    "        if isinstance(nb_features, int):\n",
    "            if nb_levels is None:\n",
    "                raise ValueError('must provide unet nb_levels if nb_features is an integer')\n",
    "            feats = np.round(nb_features * feat_mult ** np.arange(nb_levels)).astype(int)\n",
    "            nb_features = [\n",
    "                np.repeat(feats[:-1], nb_conv_per_level),\n",
    "                np.repeat(np.flip(feats), nb_conv_per_level)\n",
    "            ]\n",
    "        elif nb_levels is not None:\n",
    "            raise ValueError('cannot use nb_levels if nb_features is not an integer')\n",
    "\n",
    "        # extract any surplus (full resolution) decoder convolutions\n",
    "        enc_nf, dec_nf = nb_features\n",
    "        nb_dec_convs = len(enc_nf)\n",
    "        final_convs = dec_nf[nb_dec_convs:]\n",
    "        dec_nf = dec_nf[:nb_dec_convs]\n",
    "        self.nb_levels = int(nb_dec_convs / nb_conv_per_level) + 1\n",
    "\n",
    "        if isinstance(max_pool, int):\n",
    "            max_pool = [max_pool] * self.nb_levels\n",
    "\n",
    "        # cache downsampling / upsampling operations\n",
    "        MaxPooling = getattr(nn, 'MaxPool%dd' % ndims)\n",
    "        self.pooling = [MaxPooling(s) for s in max_pool]\n",
    "        self.upsampling = [lambda x, ref: F.interpolate(x, size=ref.shape[2:], mode='nearest') for _ in max_pool]\n",
    "\n",
    "        # configure encoder (down-sampling path)\n",
    "        prev_nf = infeats\n",
    "        encoder_nfs = [prev_nf]\n",
    "        self.encoder = nn.ModuleList()\n",
    "        for level in range(self.nb_levels - 1):\n",
    "            convs = nn.ModuleList()\n",
    "            for conv in range(nb_conv_per_level):\n",
    "                nf = enc_nf[level * nb_conv_per_level + conv]\n",
    "                convs.append(ConvBlock(ndims, prev_nf, nf))\n",
    "                prev_nf = nf\n",
    "            self.encoder.append(convs)\n",
    "            encoder_nfs.append(prev_nf)\n",
    "\n",
    "        # configure decoder (up-sampling path)\n",
    "        encoder_nfs = np.flip(encoder_nfs)\n",
    "        self.decoder = nn.ModuleList()\n",
    "        for level in range(self.nb_levels - 1):\n",
    "            convs = nn.ModuleList()\n",
    "            for conv in range(nb_conv_per_level):\n",
    "                nf = dec_nf[level * nb_conv_per_level + conv]\n",
    "                convs.append(ConvBlock(ndims, prev_nf, nf))\n",
    "                prev_nf = nf\n",
    "            self.decoder.append(convs)\n",
    "            if not half_res or level < (self.nb_levels - 2):\n",
    "                prev_nf += encoder_nfs[level]\n",
    "\n",
    "        # now we take care of any remaining convolutions\n",
    "        self.remaining = nn.ModuleList()\n",
    "        for num, nf in enumerate(final_convs):\n",
    "            self.remaining.append(ConvBlock(ndims, prev_nf, nf))\n",
    "            prev_nf = nf\n",
    "\n",
    "        self.apply(InitWeights_He())\n",
    "\n",
    "        self.final = nn.Conv3d(prev_nf, ndims, kernel_size=3, padding=1)\n",
    "        self.final.weight = nn.Parameter(Normal(0, 1e-5).sample(self.final.weight.shape))\n",
    "        self.final.bias = nn.Parameter(torch.zeros(self.final.bias.shape))\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # encoder forward pass\n",
    "        x_history = [x]\n",
    "        for level, convs in enumerate(self.encoder):\n",
    "            for conv in convs:\n",
    "                x = conv(x)\n",
    "            x_history.append(x)\n",
    "            x = self.pooling[level](x)\n",
    "\n",
    "        # decoder forward pass with upsampling and concatenation\n",
    "        for level, convs in enumerate(self.decoder):\n",
    "            for conv in convs:\n",
    "                x = conv(x)\n",
    "            if not self.half_res or level < (self.nb_levels - 2):\n",
    "                skip = x_history.pop()\n",
    "                x = self.upsampling[level](x, skip)\n",
    "                x = torch.cat([x, skip], dim=1)\n",
    "\n",
    "        # remaining convs at full resolution\n",
    "        for conv in self.remaining:\n",
    "            x = conv(x)\n",
    "\n",
    "        return self.final(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T04:12:10.343317Z",
     "iopub.status.busy": "2025-06-02T04:12:10.343031Z",
     "iopub.status.idle": "2025-06-02T04:12:10.364589Z",
     "shell.execute_reply": "2025-06-02T04:12:10.363977Z",
     "shell.execute_reply.started": "2025-06-02T04:12:10.343294Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def jacobian(disp):\n",
    "    \"\"\"\n",
    "    Compute the jacobian of a displacement field B, 3, X, Y, Z\n",
    "    \"\"\"\n",
    "    d_dx = disp[:, :, 1:, :-1, :-1] - disp[:, :, :-1, :-1, :-1]\n",
    "    d_dy = disp[:, :, :-1, 1:, :-1] - disp[:, :, :-1, :-1, :-1]\n",
    "    d_dz = disp[:, :, :-1, :-1, 1:] - disp[:, :, :-1, :-1, :-1]\n",
    "    jac = torch.stack([d_dx, d_dy, d_dz], dim=1) # B, [ddisp_./dx, disp_./dy, ddisp_./dz], [ddisp_x/d., ddisp_y/d., ddisp_z/d.], X, Y, Z\n",
    "    return F.pad(jac, (0, 1, 0, 1, 0, 1)) # B, 3, 3, X, Y, Z\n",
    "\n",
    "def Jacobian_det(disp):\n",
    "    \"\"\"\n",
    "    Computes mean jacobian determinant of the deformation field, given displacement field\n",
    "    \"\"\"\n",
    "    jac = jacobian((disp)[:, [2, 1, 0]])\n",
    "    jac[:, 0, 0] += 1.0\n",
    "    jac[:, 1, 1] += 1.0\n",
    "    jac[:, 2, 2] += 1.0\n",
    "    det = (\n",
    "        jac[:, 0, 0] * jac[:, 1, 1] * jac[:, 2, 2] +\n",
    "        jac[:, 0, 1] * jac[:, 1, 2] * jac[:, 2, 0] +\n",
    "        jac[:, 0, 2] * jac[:, 1, 0] * jac[:, 2, 1] -\n",
    "        jac[:, 0, 0] * jac[:, 1, 2] * jac[:, 2, 1] - \n",
    "        jac[:, 0, 1] * jac[:, 1, 0] * jac[:, 2, 2] -\n",
    "        jac[:, 0, 2] * jac[:, 1, 1] * jac[:, 2, 0]\n",
    "    )\n",
    "    return ((det-1)**2).mean()\n",
    "\n",
    "def Hessian_penalty(ddf):\n",
    "    \"\"\"\n",
    "    Computes bending energy of the displacement field\n",
    "    \"\"\"\n",
    "    jac = jacobian(ddf) # B, 3, 3, X, Y, Z\n",
    "    B, _, __, X, Y, Z = jac.size()\n",
    "    hess = jacobian(torch.reshape(jac, (B, -1, X, Y, Z)))\n",
    "    return (hess**2).sum((1,2)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T04:13:28.598497Z",
     "iopub.status.busy": "2025-06-02T04:13:28.597886Z",
     "iopub.status.idle": "2025-06-02T04:13:28.662154Z",
     "shell.execute_reply": "2025-06-02T04:13:28.661418Z",
     "shell.execute_reply.started": "2025-06-02T04:13:28.598477Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train(data, model, loss_fn, optimizer, epoch, writer):\n",
    "    model.train()\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    epoch_mse = 0.0\n",
    "    epoch_hess = 0.0\n",
    "    epoch_total_loss = 0.0\n",
    "    epoch_initial_mask_mse = 0.0\n",
    "    epoch_initial_whole_mse = 0.0\n",
    "    epoch_full_mse = 0.0\n",
    "    \n",
    "    running_mse = 0.0\n",
    "    running_hess = 0.0\n",
    "    running_total_loss = 0.0\n",
    "    \n",
    "    len_cases = len(data)\n",
    "    \n",
    "    for i, (img, init_ddf, gt_ddf, mask) in enumerate(tqdm(data, leave=False)):\n",
    "        gt_ddf = gt_ddf.to(device)\n",
    "        mask = mask.to(device)\n",
    "        mask = mask > 0\n",
    "        mask = mask.squeeze(0)\n",
    "\n",
    "        epoch_initial_whole_mse += loss_fn(init_ddf.to(device), gt_ddf).item()\n",
    "        epoch_initial_mask_mse += loss_fn(torch.where(mask, init_ddf.to(device), 0.0), torch.where(mask, gt_ddf, 0.0)).item()\n",
    "        \n",
    "        inputs = torch.cat([img, init_ddf], dim=1).to(device)\n",
    "\n",
    "        pred_ddf = model(inputs)\n",
    "        hess = Hessian_penalty(pred_ddf)\n",
    "        mse = loss_fn(pred_ddf, gt_ddf)\n",
    "        #hess = Hessian_penalty(torch.where(mask, pred_ddf, 0.0))\n",
    "        #mse = loss_fn(torch.where(mask, pred_ddf, 0.0), torch.where(mask, gt_ddf, 0.0)) #+ 20 * hess\n",
    "        total_loss = mse + 150 * hess\n",
    "\n",
    "        running_mse += mse.item()\n",
    "        running_hess += hess.item()\n",
    "        running_total_loss += total_loss.item()\n",
    "        epoch_mse += loss_fn(torch.where(mask, pred_ddf, 0.0), torch.where(mask, gt_ddf, 0.0)).item()\n",
    "        epoch_full_mse += mse.item()\n",
    "        epoch_hess += hess.item()\n",
    "        epoch_total_loss += total_loss.item()\n",
    "\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if i % 50 == 49:\n",
    "            writer.add_scalar(\"training_mse\", running_mse / 50, epoch * len_cases + i)\n",
    "            writer.add_scalar(\"training_hess\", running_hess / 50, epoch * len_cases + i)\n",
    "            writer.add_scalar(\"training_loss\", running_total_loss / 50, epoch * len_cases + i)\n",
    "            running_mse = 0.0\n",
    "            running_hess = 0.0\n",
    "            running_total_loss = 0.0\n",
    "    \n",
    "    tqdm.write(f\"Initial MSE (whole): {epoch_initial_whole_mse / len_cases}\")\n",
    "    tqdm.write(f\"Initial MSE (mask): {epoch_initial_mask_mse / len_cases}\")\n",
    "    tqdm.write(f\"Epoch MSE (whole): {epoch_full_mse / len_cases}\")\n",
    "    tqdm.write(f\"Epoch MSE (mask): {epoch_mse / len_cases}\")\n",
    "    tqdm.write(f\"Epoch Hessian: {epoch_hess / len_cases}\")\n",
    "    tqdm.write(f\"Epoch Loss: {epoch_total_loss / len_cases}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T04:13:28.752541Z",
     "iopub.status.busy": "2025-06-02T04:13:28.751564Z",
     "iopub.status.idle": "2025-06-02T04:13:28.764204Z",
     "shell.execute_reply": "2025-06-02T04:13:28.763148Z",
     "shell.execute_reply.started": "2025-06-02T04:13:28.752510Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate(data, model, loss_fn, epoch, writer):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    val_mse = 0.0\n",
    "    val_hess = 0.0\n",
    "    val_total_loss = 0.0\n",
    "    val_initial_mask_mse = 0.0\n",
    "    val_initial_whole_mse = 0.0\n",
    "    val_full_mse = 0.0\n",
    "    \n",
    "    running_mse = 0.0\n",
    "    running_hess = 0.0\n",
    "    running_total_loss = 0.0\n",
    "    \n",
    "    len_cases = len(data)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (img, init_ddf, y, mask) in enumerate(tqdm(data, leave=False)):\n",
    "            gt_ddf = gt_ddf.to(device)\n",
    "            mask = mask.to(device)\n",
    "            mask = mask > 0\n",
    "            mask = mask.squeeze(0)\n",
    "    \n",
    "            val_initial_whole_mse += loss_fn(init_ddf.to(device), gt_ddf).item()\n",
    "            val_initial_mask_mse += loss_fn(torch.where(mask, init_ddf.to(device), 0.0), torch.where(mask, gt_ddf, 0.0)).item()\n",
    "            \n",
    "            inputs = torch.cat([img, init_ddf], dim=1).to(device)\n",
    "    \n",
    "            pred_ddf = model(inputs)\n",
    "            hess = Hessian_penalty(pred_ddf)\n",
    "            mse = loss_fn(pred_ddf, gt_ddf)\n",
    "            #hess = Hessian_penalty(torch.where(mask, pred_ddf, 0.0))\n",
    "            #mse = loss_fn(torch.where(mask, pred_ddf, 0.0), torch.where(mask, gt_ddf, 0.0))\n",
    "            total_loss = mse + 150 * hess\n",
    "    \n",
    "            running_mse += mse.item()\n",
    "            running_hess += hess.item()\n",
    "            running_total_loss += total_loss.item()\n",
    "            val_mse += loss_fn(torch.where(mask, pred_ddf, 0.0), torch.where(mask, gt_ddf, 0.0)).item()\n",
    "            val_hess += hess.item()\n",
    "            val_total_loss += total_loss.item()\n",
    "            val_full_mse += mse.item()\n",
    "    \n",
    "            if i % 10 == 9:\n",
    "                writer.add_scalar(\"validation_mse\", running_mse / 10, epoch * len_cases + i)\n",
    "                writer.add_scalar(\"validation_hess\", running_hess / 10, epoch * len_cases + i)\n",
    "                writer.add_scalar(\"validation_loss\", running_total_loss / 10, epoch * len_cases + i)\n",
    "                running_mse = 0.0\n",
    "                running_hess = 0.0\n",
    "                running_total_loss = 0.0\n",
    "                \n",
    "    tqdm.write(f\"Initial MSE (whole): {val_initial_whole_mse / len_cases}\")            \n",
    "    tqdm.write(f\"Initial MSE (mask): {val_initial_mask_mse / len_cases}\")\n",
    "    tqdm.write(f\"Val MSE (whole): {val_full_mse / len_cases}\")\n",
    "    tqdm.write(f\"Val MSE (mask): {val_mse / len_cases}\")\n",
    "    tqdm.write(f\"Val Hessian: {val_hess / len_cases}\")\n",
    "    tqdm.write(f\"Val Loss: {val_total_loss / len_cases}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T04:13:38.349735Z",
     "iopub.status.busy": "2025-06-02T04:13:38.349440Z",
     "iopub.status.idle": "2025-06-02T04:13:38.357405Z",
     "shell.execute_reply": "2025-06-02T04:13:38.356878Z",
     "shell.execute_reply.started": "2025-06-02T04:13:38.349715Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "interp = 'linear'\n",
    "norm = 'min-max'\n",
    "\n",
    "dataset = NeuriPhyDataset(\"/kaggle/input/neuriphy/Training\", ddf_interpolator=interp, normalization=norm)\n",
    "train_dataset, val_dataset = random_split(dataset, [0.85, 0.15], generator=torch.Generator().manual_seed(13))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T04:13:40.261406Z",
     "iopub.status.busy": "2025-06-02T04:13:40.261135Z",
     "iopub.status.idle": "2025-06-02T04:13:40.267355Z",
     "shell.execute_reply": "2025-06-02T04:13:40.266702Z",
     "shell.execute_reply.started": "2025-06-02T04:13:40.261384Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "run_name = \"cosanneal_lesskpts_\"\n",
    "run_name += f\"{interp}+{norm}\" if norm is not None else f\"{interp}+no_norm\"\n",
    "writer = SummaryWriter(f\"/kaggle/working/runs/{run_name}\")\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T04:13:41.661449Z",
     "iopub.status.busy": "2025-06-02T04:13:41.660935Z",
     "iopub.status.idle": "2025-06-02T04:13:41.677695Z",
     "shell.execute_reply": "2025-06-02T04:13:41.677081Z",
     "shell.execute_reply.started": "2025-06-02T04:13:41.661427Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "size = (240,240,155)\n",
    "in_channels = 4\n",
    "epochs = 20\n",
    "\n",
    "model = Unet(size, in_channels).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "#scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs, eta_min=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T04:13:43.166987Z",
     "iopub.status.busy": "2025-06-02T04:13:43.166444Z",
     "iopub.status.idle": "2025-06-02T04:25:39.798764Z",
     "shell.execute_reply": "2025-06-02T04:25:39.797430Z",
     "shell.execute_reply.started": "2025-06-02T04:13:43.166963Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for e in tqdm(range(epochs)):\n",
    "    train(train_dataloader, model, loss_fn, optimizer, e, writer)\n",
    "    if e % 3 == 2:\n",
    "        evaluate(val_dataloader, model, loss_fn, e, writer)\n",
    "    #scheduler.step()\n",
    "evaluate(val_dataloader, model, loss_fn, e, writer)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-29T23:36:47.543521Z",
     "iopub.status.idle": "2025-05-29T23:36:47.543782Z",
     "shell.execute_reply": "2025-05-29T23:36:47.543665Z",
     "shell.execute_reply.started": "2025-05-29T23:36:47.543653Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#%load_ext tensorboard\n",
    "#%tensorboard --logdir /kaggle/working/runs"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7540513,
     "sourceId": 11988615,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
