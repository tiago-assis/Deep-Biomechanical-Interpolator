# Author: 
# Tiago Assis
# Faculty of Sciences, University of Lisbon
# March 2025

import sys
import os
import shutil
import glob
import time
import datetime
from natsort import natsorted
import simulation_pipeline.generate_meshes as generate_meshes
import simulation_pipeline.find_gravity_vectors as find_gravity_vectors
import simulation_pipeline.identify_tumor as identify_tumor
import simulation_pipeline.reconstruct_model as reconstruct_model
import simulation_pipeline.define_skull_boundaries as define_skull_boundaries
import simulation_pipeline.generate_integration_points as generate_integration_points
import simulation_pipeline.assign_material_properties as assign_material_properties


def main(input_path: str) -> None:
    """
    Runs the pre-simulation pipeline for all patient cases in the specified input directory to generate the necessary
    inputs for the MTLED solver.

    Args:
        input_path (str): Path to the root directory containing individual patient case folders.
    """
    big_start = time.time()

    cases = natsorted(os.listdir(input_path))

    for case in cases:
        cwd = os.getcwd()
        case_path = os.path.join(cwd, input_path, case)
        
        if os.path.exists(os.path.join(case_path, "mtled_inputs")) and len(os.listdir(os.path.join(case_path, "mtled_inputs"))) > 0:
            print(f"MTLED inputs already generated for case '{case}'")
            continue

        # Find input files
        brain_surface = glob.glob(os.path.join(case_path, "SurfaceModel*.stl"))[0]
        tumor_mask = glob.glob(os.path.join(case_path, "tumor*.seg.nrrd"))[0]
        brain_mask = glob.glob(os.path.join(case_path, "brain_mask*.seg.nrrd"))[0]
        brain_volume = glob.glob(os.path.join(case_path, "*T*.nrrd"))[0]

        print(f"\nRunning case {case}...")
        try:
            # Changing working directory to not mess up the paths inside the framework scripts while running
            os.chdir(os.path.join(cwd, "simulation_pipeline"))
            
            # Deletes temporary intermediate files generated and used during the simulation pipeline
            clear_workspace()

            start = time.time()
            run_framework(brain_surface, tumor_mask, brain_mask, brain_volume)
            export_results(case_path)
            print(f"\nCase '{case}' completed in {datetime.timedelta(seconds=time.time()-start)}")
        finally:
            # Changing back to the original working directory
            os.chdir(cwd)

    print(f"\nAll cases completed in {datetime.timedelta(seconds=time.time()-big_start)}")  
      

def run_framework(brain_surface: str, tumor_mask: str, brain_mask: str, brain_volume: str) -> None:
    """
    Executes the sequential steps of the brain modeling and pre-simulation pipeline.
    Each step is handled by a separate module, which performs tasks like mesh generation,
    tumor identification, model reconstruction, and material property assignment.

    Args:
        brain_surface (str): Path to the surface model (.stl) of the brain.
        tumor_mask (str): Path to the tumor segmentation file (.nrrd).
        brain_mask (str): Path to the brain segmentation file (.nrrd).
        brain_volume (str): Path to the 3D brain image file (.nrrd).
    """
    # Generates the volumetric brain mesh
    generate_meshes.generate_mesh(os.path.abspath(brain_surface))
    # Finds possible entry points and corresponding gravity vectors
    find_gravity_vectors.main(brain_mask, tumor_mask)
    # Identifies the tumor nodes in the mesh and the boundaries of the tumor
    identify_tumor.main(tumor_mask, brain_mask)
    # Reconstructs a brain model without the tumor nodes
    reconstruct_model.reconstruct_model_without_tumor()
    # Defines the skull boundary and the contacts between brain nodes and skull nodes
    define_skull_boundaries.main()
    # Generates the mesh integration points
    generate_integration_points.main()
    # Classifies each voxel as a material (parenchyma, CSF, or tumor) and assigns their specific physical properties
    assign_material_properties.main(brain_volume)

def export_results(out_path: str) -> None:
    """
    Exports files generated by the pre-simulation pipeline necessary for the proper MTLED solver.

    Args:
        out_path (str): Path to the directory where results should be exported to.
    """
    # Creates the export directory if it doesn't already exist
    if not os.path.exists(os.path.join(out_path, "mtled_inputs", "extra_files")):
        os.makedirs(os.path.join(out_path, "mtled_inputs", "extra_files"))

    # Main input files for the simulation
    shutil.copy(os.path.join("mtled_outputs", "gravity_vectors.txt"), os.path.join(out_path, "mtled_inputs", "gravity_vectors.txt"))
    shutil.copy(os.path.join("mtled_outputs", "integration_points.txt"), os.path.join(out_path, "mtled_inputs", "integration_points.txt"))
    shutil.copy(os.path.join("mtled_outputs", "integration_points_re.txt"), os.path.join(out_path, "mtled_inputs", "integration_points_re.txt"))
    shutil.copy(os.path.join("2_tumor_idxs", "sharing_nodes.txt"), os.path.join(out_path, "mtled_inputs", "sharing_nodes.txt"))
    shutil.copy(os.path.join("3_reconstructed_idxs", "sharing_nodes_re.txt"), os.path.join(out_path, "mtled_inputs", "sharing_nodes_re.txt"))
    shutil.copy(os.path.join("4_final_brain_models", "brain_final.inp"), os.path.join(out_path, "mtled_inputs", "brain_final.inp"))
    shutil.copy(os.path.join("4_final_brain_models", "brain_final_re.inp"), os.path.join(out_path, "mtled_inputs", "brain_final_re.inp"))
    shutil.copy(os.path.join("5_material_properties", "material_properties.txt"), os.path.join(out_path, "mtled_inputs", "material_properties.txt"))
    shutil.copy(os.path.join("5_material_properties", "material_properties_re.txt"), os.path.join(out_path, "mtled_inputs", "material_properties_re.txt"))

    # Extra files sometimes useful for visualizations
    shutil.copy(os.path.join("1_brain_meshes", "brain_tetravolume.vtu"), os.path.join(out_path, "mtled_inputs", "extra_files", "brain_volume.vtu"))
    shutil.copy(os.path.join("1_brain_meshes", "brain_triangsurface.vtu"), os.path.join(out_path, "mtled_inputs","extra_files", "brain_surface.vtu"))
    shutil.copy(os.path.join("3_reconstructed_brain_models", "re_brain.vtu"), os.path.join(out_path, "mtled_inputs","extra_files", "brain_volume_wo_tumor.vtu"))
    shutil.copy(os.path.join("5_memberships", "brain_img_masked.nrrd"), os.path.join(out_path, "mtled_inputs", "extra_files", "brain_img_masked.nrrd"))
    shutil.copy(os.path.join("5_memberships", "membership_1.nrrd"), os.path.join(out_path, "mtled_inputs", "extra_files", "membership_1.nrrd"))
    shutil.copy(os.path.join("5_memberships", "membership_2.nrrd"), os.path.join(out_path, "mtled_inputs", "extra_files", "membership_2.nrrd"))

def clear_workspace() -> None:
    """
    Deletes all intermediate files generated within the pipeline directories,
    helping clean up temporary data to free up space for a fresh run.
    """
    if os.getcwd().endswith("simulation_pipeline"):
        for folder in os.listdir():
            if os.path.isdir(folder):
                for file in os.listdir(folder):
                    file_path = os.path.join(folder, file)
                    if os.path.isfile(file_path):
                        try:
                            os.remove(file_path)
                        except Exception as e:
                            print(f"Failed to delete {file_path}:\n{e}")
    else:
        raise IOError("Please check the current work directory")
    

if __name__ == "__main__":
    input_path = sys.argv[1]
    assert os.path.exists(input_path), "Input path does not exist."
    assert os.path.isdir(input_path), f"{input_path} is not a valid directory."
    assert len([dir for dir in os.listdir(input_path)]) > 0, "Input path is empty."
    main(input_path)
